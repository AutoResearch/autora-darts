
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../fan_out/">
      
      
        <link rel="next" href="../operations/">
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.8">
    
    
      
        <title>model_search - AutoRA DARTS Theorist</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.ded33207.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#autora.theorist.darts.model_search" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="AutoRA DARTS Theorist" class="md-header__button md-logo" aria-label="AutoRA DARTS Theorist" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AutoRA DARTS Theorist
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              model_search
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/autoresearch/autora-darts" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="AutoRA DARTS Theorist" class="md-nav__button md-logo" aria-label="AutoRA DARTS Theorist" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AutoRA DARTS Theorist
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/autoresearch/autora-darts" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../quickstart/" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../how_it_works/" class="md-nav__link">
        How it works
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../meta_parameters/" class="md-nav__link">
        Meta parameters
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../search_space/" class="md-nav__link">
        Search space
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../example/" class="md-nav__link">
        Basic Usage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../weber/" class="md-nav__link">
        Weber-Fechner Law
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          Code Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Code Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
          autora
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7_1">
          <span class="md-nav__icon md-icon"></span>
          autora
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_7_1_1" id="__nav_7_1_1_label" tabindex="0">
          theorist
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7_1_1">
          <span class="md-nav__icon md-icon"></span>
          theorist
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1_1_1" checked>
      
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">darts</a>
          
            <label for="__nav_7_1_1_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_7_1_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_7_1_1_1">
          <span class="md-nav__icon md-icon"></span>
          darts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../architect/" class="md-nav__link">
        architect
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dataset/" class="md-nav__link">
        dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../fan_out/" class="md-nav__link">
        fan_out
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          model_search
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        model_search
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search" class="md-nav__link">
    autora.theorist.darts.model_search
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell" class="md-nav__link">
    Cell
  </a>
  
    <nav class="md-nav" aria-label="Cell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.DARTSType" class="md-nav__link">
    DARTSType
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp" class="md-nav__link">
    MixedOp
  </a>
  
    <nav class="md-nav" aria-label="MixedOp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network" class="md-nav__link">
    Network
  </a>
  
    <nav class="md-nav" aria-label="Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.apply_weight_decay_to_classifier" class="md-nav__link">
    apply_weight_decay_to_classifier()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.arch_parameters" class="md-nav__link">
    arch_parameters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.architecture_to_str_list" class="md-nav__link">
    architecture_to_str_list()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.count_parameters" class="md-nav__link">
    count_parameters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.fix_architecture" class="md-nav__link">
    fix_architecture()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.genotype" class="md-nav__link">
    genotype()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.max_alphas_normal" class="md-nav__link">
    max_alphas_normal()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.new" class="md-nav__link">
    new()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.sample_alphas_normal" class="md-nav__link">
    sample_alphas_normal()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../operations/" class="md-nav__link">
        operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../regressor/" class="md-nav__link">
        regressor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../visualize/" class="md-nav__link">
        visualize
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search" class="md-nav__link">
    autora.theorist.darts.model_search
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell" class="md-nav__link">
    Cell
  </a>
  
    <nav class="md-nav" aria-label="Cell">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Cell.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.DARTSType" class="md-nav__link">
    DARTSType
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp" class="md-nav__link">
    MixedOp
  </a>
  
    <nav class="md-nav" aria-label="MixedOp">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.MixedOp.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network" class="md-nav__link">
    Network
  </a>
  
    <nav class="md-nav" aria-label="Network">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.apply_weight_decay_to_classifier" class="md-nav__link">
    apply_weight_decay_to_classifier()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.arch_parameters" class="md-nav__link">
    arch_parameters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.architecture_to_str_list" class="md-nav__link">
    architecture_to_str_list()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.count_parameters" class="md-nav__link">
    count_parameters()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.fix_architecture" class="md-nav__link">
    fix_architecture()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.genotype" class="md-nav__link">
    genotype()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.max_alphas_normal" class="md-nav__link">
    max_alphas_normal()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.new" class="md-nav__link">
    new()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autora.theorist.darts.model_search.Network.sample_alphas_normal" class="md-nav__link">
    sample_alphas_normal()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>model_search</h1>

<div class="doc doc-object doc-module">


<a id="autora.theorist.darts.model_search"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="autora.theorist.darts.model_search.Cell" class="doc doc-heading">
        <code>Cell</code>


</h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>A cell as defined in differentiable architecture search. A single cell corresponds
to a computation graph with the number of input nodes defined by n_input_states and
the number of hidden nodes defined by steps. Input nodes only project to hidden nodes and hidden
nodes project to each other with an acyclic connectivity pattern. The output of a cell
corresponds to the concatenation of all hidden nodes. Hidden nodes are computed by integrating
transformed outputs from sending nodes. Outputs from sending nodes correspond to
mixture operations, i.e. a weighted combination of pre-specified operations applied to the
variable specified by the sending node (see MixedOp).</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>_steps</code></td>
          <td>
          </td>
          <td><p>number of hidden nodes</p></td>
        </tr>
        <tr>
          <td><code>_n_input_states</code></td>
          <td>
          </td>
          <td><p>number of input nodes</p></td>
        </tr>
        <tr>
          <td><code>_ops</code></td>
          <td>
          </td>
          <td><p>list of mixture operations (amounts to the list of edges in the cell)</p></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Cell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A cell as defined in differentiable architecture search. A single cell corresponds</span>
<span class="sd">    to a computation graph with the number of input nodes defined by n_input_states and</span>
<span class="sd">    the number of hidden nodes defined by steps. Input nodes only project to hidden nodes and hidden</span>
<span class="sd">    nodes project to each other with an acyclic connectivity pattern. The output of a cell</span>
<span class="sd">    corresponds to the concatenation of all hidden nodes. Hidden nodes are computed by integrating</span>
<span class="sd">    transformed outputs from sending nodes. Outputs from sending nodes correspond to</span>
<span class="sd">    mixture operations, i.e. a weighted combination of pre-specified operations applied to the</span>
<span class="sd">    variable specified by the sending node (see MixedOp).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        _steps: number of hidden nodes</span>
<span class="sd">        _n_input_states: number of input nodes</span>
<span class="sd">        _ops: list of mixture operations (amounts to the list of edges in the cell)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">n_input_states</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a cell based on the number of hidden nodes (steps)</span>
<span class="sd">        and the number of input nodes (n_input_states).</span>

<span class="sd">        Arguments:</span>
<span class="sd">            steps: number of hidden nodes</span>
<span class="sd">            n_input_states: number of input nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The first and second nodes of cell k are set equal to the outputs of</span>
        <span class="c1"># cell k − 2 and cell k − 1, respectively, and 1 × 1 convolutions</span>
        <span class="c1"># (ReLUConvBN) are inserted as necessary</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Cell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># set parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">=</span> <span class="n">steps</span>  <span class="c1"># hidden nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">=</span> <span class="n">n_input_states</span>  <span class="c1"># input nodes</span>

        <span class="c1"># EDIT 11/04/19 SM: adapting to new SimpleNet data (changed from</span>
        <span class="c1"># multiplier to steps)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="o">=</span> <span class="n">steps</span>

        <span class="c1"># set operations according to number of modules (empty)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="c1"># iterate over edges: edges between each hidden node and input nodes +</span>
        <span class="c1"># prev hidden nodes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>  <span class="c1"># hidden nodes</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">+</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># 2 refers to the 2 input nodes</span>
                <span class="c1"># defines the stride for link between cells</span>
                <span class="c1"># adds a mixed operation (derived from architecture parameters alpha)</span>
                <span class="c1"># for 4 intermediate nodes, a total of 14 connections</span>
                <span class="c1"># (MixedOps) is added</span>
                <span class="n">op</span> <span class="o">=</span> <span class="n">MixedOp</span><span class="p">(</span><span class="n">primitives</span><span class="p">)</span>
                <span class="c1"># appends cell with mixed operation</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_states</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the output of a cell given a list of input states</span>
<span class="sd">        (variables represented in input nodes) and a weight matrix specifying the weights of each</span>
<span class="sd">        operation for each edge.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            input_states: list of input nodes</span>
<span class="sd">            weights: matrix specifying architecture weights, i.e. the weights associated</span>
<span class="sd">                with each operation for each edge</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># initialize states (activities of each node in the cell)</span>
        <span class="n">states</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

        <span class="c1"># add each input node to the number of states</span>
        <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_states</span><span class="p">:</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

        <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># this computes the states from intermediate nodes and adds them to the list of states</span>
        <span class="c1"># (values of nodes)</span>
        <span class="c1"># for each hidden node, compute edge between existing states (input</span>
        <span class="c1"># nodes / previous hidden) nodes and current node</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
        <span class="p">):</span>  <span class="c1"># compute the state for each hidden node, first hidden node is</span>
            <span class="c1"># sum of input nodes, second is sum of input and first hidden</span>
            <span class="n">s</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="n">j</span><span class="p">](</span><span class="n">h</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="n">j</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">offset</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
            <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

        <span class="c1"># concatenates the states of the last n (self._multiplier) intermediate</span>
        <span class="c1"># nodes to get the output of a cell</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Cell.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_input_states</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">primitives</span><span class="o">=</span><span class="n">PRIMITIVES</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes a cell based on the number of hidden nodes (steps)
and the number of input nodes (n_input_states).</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>steps</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of hidden nodes</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
        <tr>
          <td><code>n_input_states</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of input nodes</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">n_input_states</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a cell based on the number of hidden nodes (steps)</span>
<span class="sd">    and the number of input nodes (n_input_states).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        steps: number of hidden nodes</span>
<span class="sd">        n_input_states: number of input nodes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># The first and second nodes of cell k are set equal to the outputs of</span>
    <span class="c1"># cell k − 2 and cell k − 1, respectively, and 1 × 1 convolutions</span>
    <span class="c1"># (ReLUConvBN) are inserted as necessary</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Cell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># set parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">=</span> <span class="n">steps</span>  <span class="c1"># hidden nodes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">=</span> <span class="n">n_input_states</span>  <span class="c1"># input nodes</span>

    <span class="c1"># EDIT 11/04/19 SM: adapting to new SimpleNet data (changed from</span>
    <span class="c1"># multiplier to steps)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="o">=</span> <span class="n">steps</span>

    <span class="c1"># set operations according to number of modules (empty)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="c1"># iterate over edges: edges between each hidden node and input nodes +</span>
    <span class="c1"># prev hidden nodes</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>  <span class="c1"># hidden nodes</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">+</span> <span class="n">i</span><span class="p">):</span>  <span class="c1"># 2 refers to the 2 input nodes</span>
            <span class="c1"># defines the stride for link between cells</span>
            <span class="c1"># adds a mixed operation (derived from architecture parameters alpha)</span>
            <span class="c1"># for 4 intermediate nodes, a total of 14 connections</span>
            <span class="c1"># (MixedOps) is added</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">MixedOp</span><span class="p">(</span><span class="n">primitives</span><span class="p">)</span>
            <span class="c1"># appends cell with mixed operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Cell.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">input_states</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the output of a cell given a list of input states
(variables represented in input nodes) and a weight matrix specifying the weights of each
operation for each edge.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_states</code></td>
          <td>
                <code><span title="typing.List">List</span></code>
          </td>
          <td><p>list of input nodes</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>weights</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>matrix specifying architecture weights, i.e. the weights associated
with each operation for each edge</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_states</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the output of a cell given a list of input states</span>
<span class="sd">    (variables represented in input nodes) and a weight matrix specifying the weights of each</span>
<span class="sd">    operation for each edge.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        input_states: list of input nodes</span>
<span class="sd">        weights: matrix specifying architecture weights, i.e. the weights associated</span>
<span class="sd">            with each operation for each edge</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># initialize states (activities of each node in the cell)</span>
    <span class="n">states</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

    <span class="c1"># add each input node to the number of states</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">input_states</span><span class="p">:</span>
        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

    <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># this computes the states from intermediate nodes and adds them to the list of states</span>
    <span class="c1"># (values of nodes)</span>
    <span class="c1"># for each hidden node, compute edge between existing states (input</span>
    <span class="c1"># nodes / previous hidden) nodes and current node</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
    <span class="p">):</span>  <span class="c1"># compute the state for each hidden node, first hidden node is</span>
        <span class="c1"># sum of input nodes, second is sum of input and first hidden</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="n">j</span><span class="p">](</span><span class="n">h</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="n">j</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">offset</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

    <span class="c1"># concatenates the states of the last n (self._multiplier) intermediate</span>
    <span class="c1"># nodes to get the output of a cell</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="autora.theorist.darts.model_search.DARTSType" class="doc doc-heading">
        <code>DARTSType</code>


</h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code>str</code>, <code><span title="enum.Enum">Enum</span></code></p>

  
      <p>Enumerator that indexes different variants of DARTS.</p>


        <details class="quote">
          <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DARTSType</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enumerator that indexes different variants of DARTS.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Liu, Simonyan &amp; Yang (2018). Darts: Differentiable architecture search</span>
    <span class="n">ORIGINAL</span> <span class="o">=</span> <span class="s2">&quot;original&quot;</span>

    <span class="c1"># Chu, Zhou, Zhang &amp; Li (2020). Fair darts: Eliminating unfair advantages</span>
    <span class="c1"># in differentiable architecture search</span>
    <span class="n">FAIR</span> <span class="o">=</span> <span class="s2">&quot;fair&quot;</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="autora.theorist.darts.model_search.MixedOp" class="doc doc-heading">
        <code>MixedOp</code>


</h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Mixture operation as applied in Differentiable Architecture Search (DARTS).
A mixture operation amounts to a weighted mixture of a pre-defined set of operations
that is applied to an input variable.</p>


        <details class="quote">
          <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MixedOp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mixture operation as applied in Differentiable Architecture Search (DARTS).</span>
<span class="sd">    A mixture operation amounts to a weighted mixture of a pre-defined set of operations</span>
<span class="sd">    that is applied to an input variable.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a mixture operation based on a pre-specified set of primitive operations.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            primitives: list of primitives to be used in the mixture operation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MixedOp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="c1"># loop through all the 8 primitive operations</span>
        <span class="k">for</span> <span class="n">primitive</span> <span class="ow">in</span> <span class="n">primitives</span><span class="p">:</span>
            <span class="c1"># OPS returns an nn module for a given primitive (defines as a string)</span>
            <span class="n">op</span> <span class="o">=</span> <span class="n">operation_factory</span><span class="p">(</span><span class="n">primitive</span><span class="p">)</span>

            <span class="c1"># add the operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a mixture operation as a weighted sum of all primitive operations.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            x: input to the mixture operations</span>
<span class="sd">            weights: weight vector containing the weights associated with each operation</span>

<span class="sd">        Returns:</span>
<span class="sd">            y: result of the weighted mixture operation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># there are 8 weights for all the eight primitives. then it returns the</span>
        <span class="c1"># weighted sum of all operations performed on a given input</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.MixedOp.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">primitives</span><span class="o">=</span><span class="n">PRIMITIVES</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes a mixture operation based on a pre-specified set of primitive operations.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>primitives</code></td>
          <td>
                <code><span title="typing.Sequence">Sequence</span>[str]</code>
          </td>
          <td><p>list of primitives to be used in the mixture operation</p></td>
          <td>
                <code>PRIMITIVES</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes a mixture operation based on a pre-specified set of primitive operations.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        primitives: list of primitives to be used in the mixture operation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MixedOp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="c1"># loop through all the 8 primitive operations</span>
    <span class="k">for</span> <span class="n">primitive</span> <span class="ow">in</span> <span class="n">primitives</span><span class="p">:</span>
        <span class="c1"># OPS returns an nn module for a given primitive (defines as a string)</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">operation_factory</span><span class="p">(</span><span class="n">primitive</span><span class="p">)</span>

        <span class="c1"># add the operation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.MixedOp.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes a mixture operation as a weighted sum of all primitive operations.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>x</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>input to the mixture operations</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>weights</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>weight vector containing the weights associated with each operation</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>y</code></td>          <td>
                <code>float</code>
          </td>
          <td><p>result of the weighted mixture operation</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a mixture operation as a weighted sum of all primitive operations.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: input to the mixture operations</span>
<span class="sd">        weights: weight vector containing the weights associated with each operation</span>

<span class="sd">    Returns:</span>
<span class="sd">        y: result of the weighted mixture operation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># there are 8 weights for all the eight primitives. then it returns the</span>
    <span class="c1"># weighted sum of all operations performed on a given input</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="autora.theorist.darts.model_search.Network" class="doc doc-heading">
        <code>Network</code>


</h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>A PyTorch computation graph according to DARTS.
It consists of a single computation cell which transforms an
input vector (containing all input variable) into an output vector, by applying a set of
mixture operations which are defined by the architecture weights (labeled "alphas" of the
network).</p>
<p>The network flow looks as follows: An input vector (with _n_input_states elements) is split into
_n_input_states separate input nodes (one node per element). The input nodes are then passed
through a computation cell with _steps hidden nodes (see Cell). The output of the computation
cell corresponds to the concatenation of its hidden nodes (a single vector). The final output
corresponds to a (trained) affine transformation of this concatenation (labeled "classifier").</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>_n_input_states</code></td>
          <td>
          </td>
          <td><p>length of input vector (translates to number of input nodes)</p></td>
        </tr>
        <tr>
          <td><code>_num_classes</code></td>
          <td>
          </td>
          <td><p>length of output vector</p></td>
        </tr>
        <tr>
          <td><code>_criterion</code></td>
          <td>
          </td>
          <td><p>optimization criterion used to define the loss</p></td>
        </tr>
        <tr>
          <td><code>_steps</code></td>
          <td>
          </td>
          <td><p>number of hidden nodes in the cell</p></td>
        </tr>
        <tr>
          <td><code>_architecture_fixed</code></td>
          <td>
          </td>
          <td><p>specifies whether the architecture weights shall remain fixed
(not trained)</p></td>
        </tr>
        <tr>
          <td><code>_classifier_weight_decay</code></td>
          <td>
          </td>
          <td><p>a weight decay applied to the classifier</p></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A PyTorch computation graph according to DARTS.</span>
<span class="sd">    It consists of a single computation cell which transforms an</span>
<span class="sd">    input vector (containing all input variable) into an output vector, by applying a set of</span>
<span class="sd">    mixture operations which are defined by the architecture weights (labeled &quot;alphas&quot; of the</span>
<span class="sd">    network).</span>

<span class="sd">    The network flow looks as follows: An input vector (with _n_input_states elements) is split into</span>
<span class="sd">    _n_input_states separate input nodes (one node per element). The input nodes are then passed</span>
<span class="sd">    through a computation cell with _steps hidden nodes (see Cell). The output of the computation</span>
<span class="sd">    cell corresponds to the concatenation of its hidden nodes (a single vector). The final output</span>
<span class="sd">    corresponds to a (trained) affine transformation of this concatenation (labeled &quot;classifier&quot;).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        _n_input_states: length of input vector (translates to number of input nodes)</span>
<span class="sd">        _num_classes: length of output vector</span>
<span class="sd">        _criterion: optimization criterion used to define the loss</span>
<span class="sd">        _steps: number of hidden nodes in the cell</span>
<span class="sd">        _architecture_fixed: specifies whether the architecture weights shall remain fixed</span>
<span class="sd">            (not trained)</span>
<span class="sd">        _classifier_weight_decay: a weight decay applied to the classifier</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">n_input_states</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">architecture_fixed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">train_classifier_coefficients</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">train_classifier_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">classifier_weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">darts_type</span><span class="p">:</span> <span class="n">DARTSType</span> <span class="o">=</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">,</span>
        <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the network.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            num_classes: length of output vector</span>
<span class="sd">            criterion: optimization criterion used to define the loss</span>
<span class="sd">            steps: number of hidden nodes in the cell</span>
<span class="sd">            n_input_states: length of input vector (translates to number of input nodes)</span>
<span class="sd">            architecture_fixed: specifies whether the architecture weights shall remain fixed</span>
<span class="sd">            train_classifier_coefficients: specifies whether the classifier coefficients shall be</span>
<span class="sd">                trained</span>
<span class="sd">            train_classifier_bias: specifies whether the classifier bias shall be trained</span>
<span class="sd">            classifier_weight_decay: a weight decay applied to the classifier</span>
<span class="sd">            darts_type: variant of DARTS (regular or fair) that is applied for training</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># set parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>  <span class="c1"># number of output classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span> <span class="o">=</span> <span class="n">criterion</span>  <span class="c1"># optimization criterion (e.g., softmax)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">=</span> <span class="n">steps</span>  <span class="c1"># the number of intermediate nodes (e.g., 2)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">=</span> <span class="n">n_input_states</span>  <span class="c1"># number of input nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">=</span> <span class="n">darts_type</span>  <span class="c1"># darts variant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>  <span class="c1"># the number of internal nodes that get concatenated to the output</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span> <span class="o">=</span> <span class="n">primitives</span>

        <span class="c1"># set parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span> <span class="o">=</span> <span class="n">architecture_fixed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span> <span class="o">=</span> <span class="n">classifier_weight_decay</span>

        <span class="c1"># input nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stem</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Fan_Out</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cells</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="p">)</span>  <span class="c1"># get list of all current modules (should be empty)</span>

        <span class="c1"># generate a cell that undergoes architecture search</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cells</span> <span class="o">=</span> <span class="n">Cell</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">)</span>

        <span class="c1"># last layer is a linear classifier (e.g. with 10 CIFAR classes)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dim_output</span><span class="p">,</span> <span class="n">num_classes</span>
        <span class="p">)</span>  <span class="c1"># make this the number of input states</span>

        <span class="c1"># initialize classifier weights</span>
        <span class="k">if</span> <span class="n">train_classifier_coefficients</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">train_classifier_bias</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># initializes weights of the architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_alphas</span><span class="p">()</span>

    <span class="c1"># function for copying the network</span>
    <span class="k">def</span> <span class="nf">new</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a copy of the network.</span>

<span class="sd">        Returns:</span>
<span class="sd">            a copy of the network</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">model_new</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
            <span class="c1"># self._C, self._num_classes, self._criterion, steps=self._steps</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span><span class="p">,</span>
            <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">,</span>
            <span class="n">n_input_states</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">,</span>
            <span class="n">architecture_fixed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">,</span>
            <span class="n">classifier_weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span><span class="p">,</span>
            <span class="n">darts_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">,</span>
            <span class="n">primitives</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_new</span><span class="o">.</span><span class="n">arch_parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_parameters</span><span class="p">()):</span>
            <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_new</span>

    <span class="c1"># computes forward pass for full network</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes output of the network.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            x: input to the network</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># compute stem first</span>
        <span class="n">input_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># get architecture weights</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">FAIR</span><span class="p">:</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="s2">&quot;DARTS Type &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; not implemented&quot;</span>
                <span class="p">)</span>

        <span class="c1"># then apply cell with weights</span>
        <span class="n">cell_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="p">(</span><span class="n">input_states</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

        <span class="c1"># compute logits</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">cell_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cell_output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># just gets output to have only 2 dimensions (batch_size x num units in</span>
        <span class="c1"># output layer)</span>

        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the loss of the network for the specified criterion.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            input: input patterns</span>
<span class="sd">            target: target patterns</span>

<span class="sd">        Returns:</span>
<span class="sd">            loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># returns cross entropy by default</span>

    <span class="c1"># regularization</span>
    <span class="k">def</span> <span class="nf">apply_weight_decay_to_classifier</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies a weight decay to the weights projecting from the cell to the final output layer.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            lr: learning rate</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># weight decay proportional to degrees of freedom</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span>
                <span class="o">*</span> <span class="n">lr</span>
                <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
            <span class="p">)</span>  <span class="c1"># weight decay</span>

    <span class="k">def</span> <span class="nf">_initialize_alphas</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the architecture weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># compute the number of possible connections between nodes</span>
        <span class="n">k</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">+</span> <span class="n">i</span><span class="p">))</span>
        <span class="c1"># number of available primitive operations (8 different types for a</span>
        <span class="c1"># conv net)</span>
        <span class="n">num_ops</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">)</span>

        <span class="c1"># e.g., generate 14 (number of available edges) by 8 (operations)</span>
        <span class="c1"># weight matrix for normal alphas of the architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span>
            <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">num_ops</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># those are all the parameters of the architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_arch_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">]</span>

    <span class="c1"># provide back the architecture as a parameter</span>
    <span class="k">def</span> <span class="nf">arch_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns architecture weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _arch_parameters: architecture weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_arch_parameters</span>

    <span class="c1"># fixes architecture</span>
    <span class="k">def</span> <span class="nf">fix_architecture</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">switch</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Freezes or unfreezes the architecture weights.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            switch: set true to freeze architecture weights or false unfreeze</span>
<span class="sd">            new_weights: new set of architecture weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span> <span class="o">=</span> <span class="n">switch</span>
        <span class="k">if</span> <span class="n">new_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span> <span class="o">=</span> <span class="n">new_weights</span>
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">sample_alphas_normal</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">sample_amp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fair_darts_weight_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples an architecture from the mixed operations from a probability distribution that is</span>
<span class="sd">        defined by the (softmaxed) architecture weights.</span>
<span class="sd">        This amounts to selecting one operation per edge (i.e., setting the architecture</span>
<span class="sd">        weight of that operation to one while setting the others to zero).</span>

<span class="sd">        Arguments:</span>
<span class="sd">            sample_amp: temperature that is applied before passing the weights through a softmax</span>
<span class="sd">            fair_darts_weight_threshold: used in fair DARTS. If an architecture weight is below</span>
<span class="sd">                this value then it is set to zero.</span>

<span class="sd">        Returns:</span>
<span class="sd">            alphas_normal_sample: sampled architecture weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">alphas_normal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">alphas_normal_sample</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">:</span>
                <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample_amp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">FAIR</span><span class="p">:</span>
                <span class="n">transformed_alphas_normal</span> <span class="o">=</span> <span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span>
                <span class="n">above_threshold</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformed_alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="p">)):</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">transformed_alphas_normal</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                        <span class="o">&gt;</span> <span class="n">fair_darts_weight_threshold</span>
                    <span class="p">):</span>
                        <span class="n">above_threshold</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="n">above_threshold</span><span class="p">:</span>
                    <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">transformed_alphas_normal</span> <span class="o">*</span> <span class="n">sample_amp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">W_soft</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
                    <span class="n">W_soft</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;none&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                    <span class="s2">&quot;DARTS Type &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; not implemented&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">W_soft</span> <span class="o">!=</span> <span class="n">W_soft</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot properly sample from architecture weights due to nan entries.&quot;</span>
                <span class="p">)</span>
                <span class="n">k_sample</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W_soft</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">k_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W_soft</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">W_soft</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">alphas_normal_sample</span><span class="p">[</span><span class="n">edge</span><span class="p">,</span> <span class="n">k_sample</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">alphas_normal_sample</span>

    <span class="k">def</span> <span class="nf">max_alphas_normal</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples an architecture from the mixed operations by selecting, for each edge,</span>
<span class="sd">        the operation with the largest architecture weight.</span>

<span class="sd">        Returns:</span>
<span class="sd">            alphas_normal_sample: sampled architecture weights.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">alphas_normal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">alphas_normal_sample</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span>
            <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="n">alphas_normal_sample</span><span class="p">[</span><span class="n">edge</span><span class="p">,</span> <span class="n">max_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">alphas_normal_sample</span>

    <span class="c1"># returns the genotype of the model</span>
    <span class="k">def</span> <span class="nf">genotype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Genotype</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a genotype of the model which specifies the current computation graph based on</span>
<span class="sd">        the largest architecture weight for each edge, or based on a sample.</span>
<span class="sd">        The genotype can be used for parsing or plotting the computation graph.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            sample: if set to true, the architecture will be determined by sampling</span>
<span class="sd">                from a probability distribution that is determined by the</span>
<span class="sd">                softmaxed architecture weights. If set to false (default), the architecture will be</span>
<span class="sd">                determined based on the largest architecture weight per edge.</span>

<span class="sd">        Returns:</span>
<span class="sd">            genotype: genotype describing the current (sampled) architecture</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># this function uses the architecture weights to retrieve the</span>
        <span class="c1"># operations with the highest weights</span>
        <span class="k">def</span> <span class="nf">_parse</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">gene</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">n</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span>
            <span class="p">)</span>  <span class="c1"># 2 ... changed this to adapt to number of input states</span>
            <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>
                <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n</span>
                <span class="n">W</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="c1"># first get all the edges for a given node, edges are sorted according to their</span>
                <span class="c1"># highest (non-none) weight, starting from the edge with the smallest heighest</span>
                <span class="c1"># weight</span>

                <span class="k">if</span> <span class="s2">&quot;none&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">:</span>
                    <span class="n">none_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">none_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

                <span class="n">edges</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="nb">max</span><span class="p">(</span>
                        <span class="n">W</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">none_index</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="c1"># for each edge, figure out which is the primitive with the</span>
                <span class="c1"># highest</span>
                <span class="k">for</span> <span class="p">(</span>
                    <span class="n">j</span>
                <span class="p">)</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>  <span class="c1"># looping through all the edges for the current node (i)</span>
                    <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
                        <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>
                        <span class="n">k_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                            <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])),</span> <span class="n">p</span><span class="o">=</span><span class="n">W_soft</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">k_best</span> <span class="o">=</span> <span class="kc">None</span>
                        <span class="c1"># looping through all the primitives</span>
                        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])):</span>
                            <span class="c1"># choose the primitive with the highest weight</span>
                            <span class="c1"># if k != self.primitives.index(&#39;none&#39;):</span>
                            <span class="c1"># EDIT SM 01/13: commented to include &quot;none&quot;</span>
                            <span class="c1"># weights in genotype</span>
                            <span class="k">if</span> <span class="n">k_best</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k_best</span><span class="p">]:</span>
                                <span class="n">k_best</span> <span class="o">=</span> <span class="n">k</span>
                        <span class="c1"># add gene (primitive, edge number)</span>
                    <span class="n">gene</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">[</span><span class="n">k_best</span><span class="p">],</span> <span class="n">j</span><span class="p">))</span>
                <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
                <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">gene</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">:</span>
            <span class="n">gene_normal</span> <span class="o">=</span> <span class="n">_parse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">gene_normal</span> <span class="o">=</span> <span class="n">_parse</span><span class="p">(</span>
                <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>

        <span class="n">concat</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">genotype</span> <span class="o">=</span> <span class="n">Genotype</span><span class="p">(</span>
            <span class="n">normal</span><span class="o">=</span><span class="n">gene_normal</span><span class="p">,</span>
            <span class="n">normal_concat</span><span class="o">=</span><span class="n">concat</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">genotype</span>

    <span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">print_parameters</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Counts and returns the parameters (coefficients) of the architecture defined by the</span>
<span class="sd">        highest architecture weights.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            print_parameters: if set to true, the function will print all parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            n_params_total: total number of parameters</span>
<span class="sd">            n_params_base: number of parameters determined by the classifier</span>
<span class="sd">            param_list: list of parameters specifying the corresponding edge (operation)</span>
<span class="sd">                and value</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># counts only parameters of operations with the highest architecture weight</span>
        <span class="n">n_params_total</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># count classifier</span>
        <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="c1"># count stem</span>
        <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="n">n_params_base</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">n_params_total</span>  <span class="c1"># number of parameters, excluding individual cells</span>
        <span class="p">)</span>

        <span class="n">param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="c1"># now count number of parameters for cells that have highest</span>
        <span class="c1"># probability</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">_ops</span><span class="p">):</span>
            <span class="c1"># pick most operation with highest likelihood</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">maxIdx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">values</span> <span class="o">==</span> <span class="nb">max</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>

            <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">isiterable</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)]):</span>  <span class="c1"># Zero is not iterable</span>

                <span class="k">for</span> <span class="n">subop</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)]:</span>

                    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">subop</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                        <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
                        <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">print_parameters</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Edge (&quot;</span>
                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                    <span class="o">+</span> <span class="s2">&quot;): &quot;</span>
                    <span class="o">+</span> <span class="n">get_operation_label</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">tmp_param_list</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span>

        <span class="c1"># # get parameters from final linear classifier</span>
        <span class="c1"># tmp_param_list = list()</span>
        <span class="c1"># for parameter in self.classifier.parameters():</span>
        <span class="c1">#   for subparameter in parameter:</span>
        <span class="c1">#     tmp_param_list.append(subparameter.data.numpy().squeeze())</span>

        <span class="c1"># get parameters from final linear for each edge</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>
            <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="c1"># add weight</span>
            <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="n">edge</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="c1"># add partial bias (bias of classifier units will be divided by</span>
            <span class="c1"># number of edges)</span>
            <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">print_parameters</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;Classifier from Node &quot;</span>
                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
                    <span class="o">+</span> <span class="s2">&quot;: &quot;</span>
                    <span class="o">+</span> <span class="n">get_operation_label</span><span class="p">(</span><span class="s2">&quot;classifier_concat&quot;</span><span class="p">,</span> <span class="n">tmp_param_list</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">n_params_total</span><span class="p">,</span> <span class="n">n_params_base</span><span class="p">,</span> <span class="n">param_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">architecture_to_str_list</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_labels</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">output_labels</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">output_function_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">decimals_to_display</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">output_format</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;latex&quot;</span><span class="p">,</span> <span class="s2">&quot;console&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;console&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of strings representing the model.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            input_labels: list of strings representing the input states.</span>
<span class="sd">            output_labels: list of strings representing the output states.</span>
<span class="sd">            output_function_label: string representing the output function.</span>
<span class="sd">            decimals_to_display: number of decimals to display.</span>
<span class="sd">            output_format: if set to `&quot;console&quot;`, returns equations formatted for the command line,</span>
<span class="sd">                if set to `&quot;latex&quot;`, returns equations in latex format</span>


<span class="sd">        Returns:</span>
<span class="sd">            list of strings representing the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">n_params_total</span><span class="p">,</span> <span class="n">n_params_base</span><span class="p">,</span> <span class="n">param_list</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_parameters</span><span class="p">(</span>
            <span class="n">print_parameters</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">genotype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">genotype</span><span class="p">()</span><span class="o">.</span><span class="n">normal</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
        <span class="n">edge_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>  <span class="c1"># for every node</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n</span>
            <span class="c1"># for k in [2*i, 2*i + 1]:</span>

            <span class="n">edge_operations_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="n">op_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span>
                <span class="p">):</span>  <span class="c1"># for every edge projecting to current node</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">op</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">genotype</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">):</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">input_labels</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
                        <span class="n">u</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">u</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">op</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
                    <span class="n">op_label</span> <span class="o">=</span> <span class="n">op</span>
                    <span class="n">params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span>
                        <span class="n">start</span> <span class="o">+</span> <span class="n">j</span>
                    <span class="p">]</span>  <span class="c1"># note: genotype order and param list order don&#39;t align</span>
                    <span class="n">op_label</span> <span class="o">=</span> <span class="n">get_operation_label</span><span class="p">(</span>
                        <span class="n">op</span><span class="p">,</span>
                        <span class="n">params</span><span class="p">,</span>
                        <span class="n">decimals</span><span class="o">=</span><span class="n">decimals_to_display</span><span class="p">,</span>
                        <span class="n">input_var</span><span class="o">=</span><span class="n">u</span><span class="p">,</span>
                        <span class="n">output_format</span><span class="o">=</span><span class="n">output_format</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">op_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                    <span class="n">edge_operations_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op_label</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_operations_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">edge_str</span> <span class="o">=</span> <span class="n">v</span> <span class="o">+</span> <span class="s2">&quot; = 0&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">edge_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge_operation</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">edge_operations_list</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">edge_str</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">edge_operation</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;add&quot;</span>
                        <span class="ow">and</span> <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;subtract&quot;</span>
                        <span class="ow">and</span> <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span>
                    <span class="p">):</span>
                        <span class="n">edge_str</span> <span class="o">+=</span> <span class="s2">&quot; +&quot;</span>
                    <span class="n">edge_str</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">edge_operation</span>

            <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge_str</span><span class="p">)</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># TODO: extend to multiple outputs</span>
        <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">=</span> <span class="n">output_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">output_function_label</span>
            <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">left(&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">=</span> <span class="n">output_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">output_function_label</span>
            <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;(&quot;</span>

        <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">param_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_list</span><span class="p">)</span> <span class="o">-</span> <span class="n">steps</span> <span class="o">+</span> <span class="n">i</span>
            <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">tmp_param_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot; + &quot;</span>

            <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
                <span class="n">input_var</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_var</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">classifier_str</span> <span class="o">+=</span> <span class="n">get_operation_label</span><span class="p">(</span>
                <span class="s2">&quot;classifier&quot;</span><span class="p">,</span>
                <span class="n">tmp_param_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">decimals</span><span class="o">=</span><span class="n">decimals_to_display</span><span class="p">,</span>
                <span class="n">input_var</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot; + &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bias</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
                        <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">right)&quot;</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;)&quot;</span>

        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier_str</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">edge_list</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_input_states</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">architecture_fixed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_classifier_coefficients</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_classifier_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">classifier_weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">darts_type</span><span class="o">=</span><span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">,</span> <span class="n">primitives</span><span class="o">=</span><span class="n">PRIMITIVES</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Initializes the network.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>num_classes</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>length of output vector</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>criterion</code></td>
          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td><p>optimization criterion used to define the loss</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>steps</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of hidden nodes in the cell</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
        <tr>
          <td><code>n_input_states</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>length of input vector (translates to number of input nodes)</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
        <tr>
          <td><code>architecture_fixed</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>specifies whether the architecture weights shall remain fixed</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>train_classifier_coefficients</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>specifies whether the classifier coefficients shall be
trained</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>train_classifier_bias</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>specifies whether the classifier bias shall be trained</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>classifier_weight_decay</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>a weight decay applied to the classifier</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
        <tr>
          <td><code>darts_type</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="autora.theorist.darts.model_search.DARTSType" href="#autora.theorist.darts.model_search.DARTSType">DARTSType</a></code>
          </td>
          <td><p>variant of DARTS (regular or fair) that is applied for training</p></td>
          <td>
                <code>DARTSType.ORIGINAL</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">n_input_states</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">architecture_fixed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">train_classifier_coefficients</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">train_classifier_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">classifier_weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">darts_type</span><span class="p">:</span> <span class="n">DARTSType</span> <span class="o">=</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">,</span>
    <span class="n">primitives</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">PRIMITIVES</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the network.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        num_classes: length of output vector</span>
<span class="sd">        criterion: optimization criterion used to define the loss</span>
<span class="sd">        steps: number of hidden nodes in the cell</span>
<span class="sd">        n_input_states: length of input vector (translates to number of input nodes)</span>
<span class="sd">        architecture_fixed: specifies whether the architecture weights shall remain fixed</span>
<span class="sd">        train_classifier_coefficients: specifies whether the classifier coefficients shall be</span>
<span class="sd">            trained</span>
<span class="sd">        train_classifier_bias: specifies whether the classifier bias shall be trained</span>
<span class="sd">        classifier_weight_decay: a weight decay applied to the classifier</span>
<span class="sd">        darts_type: variant of DARTS (regular or fair) that is applied for training</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Network</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># set parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>  <span class="c1"># number of output classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span> <span class="o">=</span> <span class="n">criterion</span>  <span class="c1"># optimization criterion (e.g., softmax)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">=</span> <span class="n">steps</span>  <span class="c1"># the number of intermediate nodes (e.g., 2)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span> <span class="o">=</span> <span class="n">n_input_states</span>  <span class="c1"># number of input nodes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">=</span> <span class="n">darts_type</span>  <span class="c1"># darts variant</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">1</span>  <span class="c1"># the number of internal nodes that get concatenated to the output</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span> <span class="o">=</span> <span class="n">primitives</span>

    <span class="c1"># set parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dim_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span> <span class="o">=</span> <span class="n">architecture_fixed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span> <span class="o">=</span> <span class="n">classifier_weight_decay</span>

    <span class="c1"># input nodes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stem</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Fan_Out</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">cells</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="p">)</span>  <span class="c1"># get list of all current modules (should be empty)</span>

    <span class="c1"># generate a cell that undergoes architecture search</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cells</span> <span class="o">=</span> <span class="n">Cell</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">)</span>

    <span class="c1"># last layer is a linear classifier (e.g. with 10 CIFAR classes)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim_output</span><span class="p">,</span> <span class="n">num_classes</span>
    <span class="p">)</span>  <span class="c1"># make this the number of input states</span>

    <span class="c1"># initialize classifier weights</span>
    <span class="k">if</span> <span class="n">train_classifier_coefficients</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">train_classifier_bias</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># initializes weights of the architecture</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_alphas</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.apply_weight_decay_to_classifier" class="doc doc-heading">
<code class="highlight language-python"><span class="n">apply_weight_decay_to_classifier</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Applies a weight decay to the weights projecting from the cell to the final output layer.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>lr</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>learning rate</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">apply_weight_decay_to_classifier</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a weight decay to the weights projecting from the cell to the final output layer.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        lr: learning rate</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># weight decay proportional to degrees of freedom</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span>
            <span class="o">*</span> <span class="n">lr</span>
            <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="p">)</span>  <span class="c1"># weight decay</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.arch_parameters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">arch_parameters</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Returns architecture weights.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>_arch_parameters</code></td>          <td>
                <code><span title="typing.List">List</span></code>
          </td>
          <td><p>architecture weights.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">arch_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns architecture weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        _arch_parameters: architecture weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_arch_parameters</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.architecture_to_str_list" class="doc doc-heading">
<code class="highlight language-python"><span class="n">architecture_to_str_list</span><span class="p">(</span><span class="n">input_labels</span><span class="p">,</span> <span class="n">output_labels</span><span class="p">,</span> <span class="n">output_function_label</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">decimals_to_display</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s1">&#39;console&#39;</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Returns a list of strings representing the model.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_labels</code></td>
          <td>
                <code><span title="typing.Sequence">Sequence</span>[str]</code>
          </td>
          <td><p>list of strings representing the input states.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>output_labels</code></td>
          <td>
                <code><span title="typing.Sequence">Sequence</span>[str]</code>
          </td>
          <td><p>list of strings representing the output states.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>output_function_label</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>string representing the output function.</p></td>
          <td>
                <code>&#39;&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>decimals_to_display</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>number of decimals to display.</p></td>
          <td>
                <code>2</code>
          </td>
        </tr>
        <tr>
          <td><code>output_format</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;latex&#39;, &#39;console&#39;]</code>
          </td>
          <td><p>if set to <code>"console"</code>, returns equations formatted for the command line,
if set to <code>"latex"</code>, returns equations in latex format</p></td>
          <td>
                <code>&#39;console&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.List">List</span></code>
          </td>
          <td><p>list of strings representing the model</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">architecture_to_str_list</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_labels</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">output_labels</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">output_function_label</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="n">decimals_to_display</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">output_format</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;latex&quot;</span><span class="p">,</span> <span class="s2">&quot;console&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;console&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of strings representing the model.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        input_labels: list of strings representing the input states.</span>
<span class="sd">        output_labels: list of strings representing the output states.</span>
<span class="sd">        output_function_label: string representing the output function.</span>
<span class="sd">        decimals_to_display: number of decimals to display.</span>
<span class="sd">        output_format: if set to `&quot;console&quot;`, returns equations formatted for the command line,</span>
<span class="sd">            if set to `&quot;latex&quot;`, returns equations in latex format</span>


<span class="sd">    Returns:</span>
<span class="sd">        list of strings representing the model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span><span class="n">n_params_total</span><span class="p">,</span> <span class="n">n_params_base</span><span class="p">,</span> <span class="n">param_list</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_parameters</span><span class="p">(</span>
        <span class="n">print_parameters</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">genotype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">genotype</span><span class="p">()</span><span class="o">.</span><span class="n">normal</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span>
    <span class="n">edge_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>  <span class="c1"># for every node</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n</span>
        <span class="c1"># for k in [2*i, 2*i + 1]:</span>

        <span class="n">edge_operations_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">op_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span>
            <span class="p">):</span>  <span class="c1"># for every edge projecting to current node</span>
                <span class="n">v</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">v</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">op</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">genotype</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">):</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">input_labels</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_labels</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
                <span class="n">op_label</span> <span class="o">=</span> <span class="n">op</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span>
                    <span class="n">start</span> <span class="o">+</span> <span class="n">j</span>
                <span class="p">]</span>  <span class="c1"># note: genotype order and param list order don&#39;t align</span>
                <span class="n">op_label</span> <span class="o">=</span> <span class="n">get_operation_label</span><span class="p">(</span>
                    <span class="n">op</span><span class="p">,</span>
                    <span class="n">params</span><span class="p">,</span>
                    <span class="n">decimals</span><span class="o">=</span><span class="n">decimals_to_display</span><span class="p">,</span>
                    <span class="n">input_var</span><span class="o">=</span><span class="n">u</span><span class="p">,</span>
                    <span class="n">output_format</span><span class="o">=</span><span class="n">output_format</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">op_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="n">edge_operations_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op_label</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_operations_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">edge_str</span> <span class="o">=</span> <span class="n">v</span> <span class="o">+</span> <span class="s2">&quot; = 0&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edge_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge_operation</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">edge_operations_list</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">edge_str</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">edge_operation</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;add&quot;</span>
                    <span class="ow">and</span> <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;subtract&quot;</span>
                    <span class="ow">and</span> <span class="n">op_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span>
                <span class="p">):</span>
                    <span class="n">edge_str</span> <span class="o">+=</span> <span class="s2">&quot; +&quot;</span>
                <span class="n">edge_str</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">edge_operation</span>

        <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge_str</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># TODO: extend to multiple outputs</span>
    <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
        <span class="n">classifier_str</span> <span class="o">=</span> <span class="n">output_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">output_function_label</span>
        <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">left(&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">classifier_str</span> <span class="o">=</span> <span class="n">output_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; = &quot;</span> <span class="o">+</span> <span class="n">output_function_label</span>
        <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;(&quot;</span>

    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="n">param_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_list</span><span class="p">)</span> <span class="o">-</span> <span class="n">steps</span> <span class="o">+</span> <span class="n">i</span>
        <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">param_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">tmp_param_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot; + &quot;</span>

        <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
            <span class="n">input_var</span> <span class="o">=</span> <span class="s2">&quot;k_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_var</span> <span class="o">=</span> <span class="s2">&quot;k&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">classifier_str</span> <span class="o">+=</span> <span class="n">get_operation_label</span><span class="p">(</span>
            <span class="s2">&quot;classifier&quot;</span><span class="p">,</span>
            <span class="n">tmp_param_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">decimals</span><span class="o">=</span><span class="n">decimals_to_display</span><span class="p">,</span>
            <span class="n">input_var</span><span class="o">=</span><span class="n">input_var</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot; + &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bias</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">output_function_label</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">output_format</span> <span class="o">==</span> <span class="s2">&quot;latex&quot;</span><span class="p">:</span>
                    <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">right)&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">classifier_str</span> <span class="o">+=</span> <span class="s2">&quot;)&quot;</span>

    <span class="n">edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier_str</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">edge_list</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.count_parameters" class="doc doc-heading">
<code class="highlight language-python"><span class="n">count_parameters</span><span class="p">(</span><span class="n">print_parameters</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Counts and returns the parameters (coefficients) of the architecture defined by the
highest architecture weights.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>print_parameters</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>if set to true, the function will print all parameters.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>n_params_total</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>total number of parameters</p></td>
        </tr>
        <tr>
<td><code>n_params_base</code></td>          <td>
                <code>int</code>
          </td>
          <td><p>number of parameters determined by the classifier</p></td>
        </tr>
        <tr>
<td><code>param_list</code></td>          <td>
                <code>list</code>
          </td>
          <td><p>list of parameters specifying the corresponding edge (operation)
and value</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">print_parameters</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Counts and returns the parameters (coefficients) of the architecture defined by the</span>
<span class="sd">    highest architecture weights.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        print_parameters: if set to true, the function will print all parameters.</span>

<span class="sd">    Returns:</span>
<span class="sd">        n_params_total: total number of parameters</span>
<span class="sd">        n_params_base: number of parameters determined by the classifier</span>
<span class="sd">        param_list: list of parameters specifying the corresponding edge (operation)</span>
<span class="sd">            and value</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># counts only parameters of operations with the highest architecture weight</span>
    <span class="n">n_params_total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># count classifier</span>
    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="c1"># count stem</span>
    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="n">n_params_base</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">n_params_total</span>  <span class="c1"># number of parameters, excluding individual cells</span>
    <span class="p">)</span>

    <span class="n">param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="c1"># now count number of parameters for cells that have highest</span>
    <span class="c1"># probability</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">_ops</span><span class="p">):</span>
        <span class="c1"># pick most operation with highest likelihood</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">maxIdx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">values</span> <span class="o">==</span> <span class="nb">max</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>

        <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">isiterable</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)]):</span>  <span class="c1"># Zero is not iterable</span>

            <span class="k">for</span> <span class="n">subop</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">_ops</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)]:</span>

                <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">subop</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
                    <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="n">n_params_total</span> <span class="o">+=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">print_parameters</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Edge (&quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot;): &quot;</span>
                <span class="o">+</span> <span class="n">get_operation_label</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">[</span><span class="n">maxIdx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">tmp_param_list</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span>

    <span class="c1"># # get parameters from final linear classifier</span>
    <span class="c1"># tmp_param_list = list()</span>
    <span class="c1"># for parameter in self.classifier.parameters():</span>
    <span class="c1">#   for subparameter in parameter:</span>
    <span class="c1">#     tmp_param_list.append(subparameter.data.numpy().squeeze())</span>

    <span class="c1"># get parameters from final linear for each edge</span>
    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>
        <span class="n">tmp_param_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="c1"># add weight</span>
        <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="s2">&quot;weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="n">edge</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># add partial bias (bias of classifier units will be divided by</span>
        <span class="c1"># number of edges)</span>
        <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tmp_param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="s2">&quot;bias&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">param_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_param_list</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">print_parameters</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Classifier from Node &quot;</span>
                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
                <span class="o">+</span> <span class="s2">&quot;: &quot;</span>
                <span class="o">+</span> <span class="n">get_operation_label</span><span class="p">(</span><span class="s2">&quot;classifier_concat&quot;</span><span class="p">,</span> <span class="n">tmp_param_list</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">n_params_total</span><span class="p">,</span> <span class="n">n_params_base</span><span class="p">,</span> <span class="n">param_list</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.fix_architecture" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fix_architecture</span><span class="p">(</span><span class="n">switch</span><span class="p">,</span> <span class="n">new_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Freezes or unfreezes the architecture weights.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>switch</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>set true to freeze architecture weights or false unfreeze</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>new_weights</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[torch.<span title="torch.Tensor">Tensor</span>]</code>
          </td>
          <td><p>new set of architecture weights</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fix_architecture</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">switch</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">new_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Freezes or unfreezes the architecture weights.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        switch: set true to freeze architecture weights or false unfreeze</span>
<span class="sd">        new_weights: new set of architecture weights</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span> <span class="o">=</span> <span class="n">switch</span>
    <span class="k">if</span> <span class="n">new_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span> <span class="o">=</span> <span class="n">new_weights</span>
    <span class="k">return</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes output of the network.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>x</code></td>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>input to the network</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes output of the network.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        x: input to the network</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># compute stem first</span>
    <span class="n">input_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># get architecture weights</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">FAIR</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;DARTS Type &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; not implemented&quot;</span>
            <span class="p">)</span>

    <span class="c1"># then apply cell with weights</span>
    <span class="n">cell_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="p">(</span><span class="n">input_states</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="c1"># compute logits</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">cell_output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cell_output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="c1"># just gets output to have only 2 dimensions (batch_size x num units in</span>
    <span class="c1"># output layer)</span>

    <span class="k">return</span> <span class="n">logits</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.genotype" class="doc doc-heading">
<code class="highlight language-python"><span class="n">genotype</span><span class="p">(</span><span class="n">sample</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes a genotype of the model which specifies the current computation graph based on
the largest architecture weight for each edge, or based on a sample.
The genotype can be used for parsing or plotting the computation graph.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sample</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>if set to true, the architecture will be determined by sampling
from a probability distribution that is determined by the
softmaxed architecture weights. If set to false (default), the architecture will be
determined based on the largest architecture weight per edge.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>genotype</code></td>          <td>
                <code><span title="autora.theorist.darts.operations.Genotype">Genotype</span></code>
          </td>
          <td><p>genotype describing the current (sampled) architecture</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">genotype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Genotype</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a genotype of the model which specifies the current computation graph based on</span>
<span class="sd">    the largest architecture weight for each edge, or based on a sample.</span>
<span class="sd">    The genotype can be used for parsing or plotting the computation graph.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        sample: if set to true, the architecture will be determined by sampling</span>
<span class="sd">            from a probability distribution that is determined by the</span>
<span class="sd">            softmaxed architecture weights. If set to false (default), the architecture will be</span>
<span class="sd">            determined based on the largest architecture weight per edge.</span>

<span class="sd">    Returns:</span>
<span class="sd">        genotype: genotype describing the current (sampled) architecture</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># this function uses the architecture weights to retrieve the</span>
    <span class="c1"># operations with the highest weights</span>
    <span class="k">def</span> <span class="nf">_parse</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
        <span class="n">gene</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span>
        <span class="p">)</span>  <span class="c1"># 2 ... changed this to adapt to number of input states</span>
        <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">):</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">n</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="c1"># first get all the edges for a given node, edges are sorted according to their</span>
            <span class="c1"># highest (non-none) weight, starting from the edge with the smallest heighest</span>
            <span class="c1"># weight</span>

            <span class="k">if</span> <span class="s2">&quot;none&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">:</span>
                <span class="n">none_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">none_index</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

            <span class="n">edges</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">),</span>
                <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="nb">max</span><span class="p">(</span>
                    <span class="n">W</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">none_index</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="c1"># for each edge, figure out which is the primitive with the</span>
            <span class="c1"># highest</span>
            <span class="k">for</span> <span class="p">(</span>
                <span class="n">j</span>
            <span class="p">)</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>  <span class="c1"># looping through all the edges for the current node (i)</span>
                <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
                    <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>
                    <span class="n">k_best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])),</span> <span class="n">p</span><span class="o">=</span><span class="n">W_soft</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">k_best</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="c1"># looping through all the primitives</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">])):</span>
                        <span class="c1"># choose the primitive with the highest weight</span>
                        <span class="c1"># if k != self.primitives.index(&#39;none&#39;):</span>
                        <span class="c1"># EDIT SM 01/13: commented to include &quot;none&quot;</span>
                        <span class="c1"># weights in genotype</span>
                        <span class="k">if</span> <span class="n">k_best</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">W</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k_best</span><span class="p">]:</span>
                            <span class="n">k_best</span> <span class="o">=</span> <span class="n">k</span>
                    <span class="c1"># add gene (primitive, edge number)</span>
                <span class="n">gene</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">[</span><span class="n">k_best</span><span class="p">],</span> <span class="n">j</span><span class="p">))</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">end</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">gene</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">:</span>
        <span class="n">gene_normal</span> <span class="o">=</span> <span class="n">_parse</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gene_normal</span> <span class="o">=</span> <span class="n">_parse</span><span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="n">concat</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multiplier</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_steps</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">genotype</span> <span class="o">=</span> <span class="n">Genotype</span><span class="p">(</span>
        <span class="n">normal</span><span class="o">=</span><span class="n">gene_normal</span><span class="p">,</span>
        <span class="n">normal_concat</span><span class="o">=</span><span class="n">concat</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">genotype</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.max_alphas_normal" class="doc doc-heading">
<code class="highlight language-python"><span class="n">max_alphas_normal</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Samples an architecture from the mixed operations by selecting, for each edge,
the operation with the largest architecture weight.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>alphas_normal_sample</code></td>          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>sampled architecture weights.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">max_alphas_normal</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Samples an architecture from the mixed operations by selecting, for each edge,</span>
<span class="sd">    the operation with the largest architecture weight.</span>

<span class="sd">    Returns:</span>
<span class="sd">        alphas_normal_sample: sampled architecture weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alphas_normal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">alphas_normal_sample</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">row</span> <span class="o">=</span> <span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span>
        <span class="n">max_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">alphas_normal_sample</span><span class="p">[</span><span class="n">edge</span><span class="p">,</span> <span class="n">max_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">alphas_normal_sample</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.new" class="doc doc-heading">
<code class="highlight language-python"><span class="n">new</span><span class="p">()</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Returns a copy of the network.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code>
          </td>
          <td><p>a copy of the network</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">new</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a copy of the network.</span>

<span class="sd">    Returns:</span>
<span class="sd">        a copy of the network</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_new</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
        <span class="c1"># self._C, self._num_classes, self._criterion, steps=self._steps</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_classes</span><span class="p">,</span>
        <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_criterion</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps</span><span class="p">,</span>
        <span class="n">n_input_states</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_input_states</span><span class="p">,</span>
        <span class="n">architecture_fixed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_architecture_fixed</span><span class="p">,</span>
        <span class="n">classifier_weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_classifier_weight_decay</span><span class="p">,</span>
        <span class="n">darts_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">,</span>
        <span class="n">primitives</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_new</span><span class="o">.</span><span class="n">arch_parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_parameters</span><span class="p">()):</span>
        <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_new</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="autora.theorist.darts.model_search.Network.sample_alphas_normal" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sample_alphas_normal</span><span class="p">(</span><span class="n">sample_amp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fair_darts_weight_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Samples an architecture from the mixed operations from a probability distribution that is
defined by the (softmaxed) architecture weights.
This amounts to selecting one operation per edge (i.e., setting the architecture
weight of that operation to one while setting the others to zero).</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>sample_amp</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>temperature that is applied before passing the weights through a softmax</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>fair_darts_weight_threshold</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>used in fair DARTS. If an architecture weight is below
this value then it is set to zero.</p></td>
          <td>
                <code>0</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>alphas_normal_sample</code></td>          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td><p>sampled architecture weights.</p></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>src/autora/theorist/darts/model_search.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample_alphas_normal</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">sample_amp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fair_darts_weight_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Samples an architecture from the mixed operations from a probability distribution that is</span>
<span class="sd">    defined by the (softmaxed) architecture weights.</span>
<span class="sd">    This amounts to selecting one operation per edge (i.e., setting the architecture</span>
<span class="sd">    weight of that operation to one while setting the others to zero).</span>

<span class="sd">    Arguments:</span>
<span class="sd">        sample_amp: temperature that is applied before passing the weights through a softmax</span>
<span class="sd">        fair_darts_weight_threshold: used in fair DARTS. If an architecture weight is below</span>
<span class="sd">            this value then it is set to zero.</span>

<span class="sd">    Returns:</span>
<span class="sd">        alphas_normal_sample: sampled architecture weights.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">alphas_normal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">alphas_normal_sample</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">ORIGINAL</span><span class="p">:</span>
            <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample_amp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span> <span class="o">==</span> <span class="n">DARTSType</span><span class="o">.</span><span class="n">FAIR</span><span class="p">:</span>
            <span class="n">transformed_alphas_normal</span> <span class="o">=</span> <span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span>
            <span class="n">above_threshold</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformed_alphas_normal</span><span class="o">.</span><span class="n">data</span><span class="p">)):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">transformed_alphas_normal</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                    <span class="o">&gt;</span> <span class="n">fair_darts_weight_threshold</span>
                <span class="p">):</span>
                    <span class="n">above_threshold</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">above_threshold</span><span class="p">:</span>
                <span class="n">W_soft</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">transformed_alphas_normal</span> <span class="o">*</span> <span class="n">sample_amp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">W_soft</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">alphas_normal</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
                <span class="n">W_soft</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">primitives</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;none&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                <span class="s2">&quot;DARTS Type &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DARTS_type</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; not implemented&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">W_soft</span> <span class="o">!=</span> <span class="n">W_soft</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Cannot properly sample from architecture weights due to nan entries.&quot;</span>
            <span class="p">)</span>
            <span class="n">k_sample</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W_soft</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W_soft</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">W_soft</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">alphas_normal_sample</span><span class="p">[</span><span class="n">edge</span><span class="p">,</span> <span class="n">k_sample</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">alphas_normal_sample</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": [], "search": "../../../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.51198bba.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>